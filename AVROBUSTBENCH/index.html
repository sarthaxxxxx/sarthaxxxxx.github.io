<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AVROBUSTBENCH: Benchmarking the Robustness of Audio-Visual Recognition Models at Test-Time</h1>
            <div class="has-text-centered" style="margin-top: 0.75rem;">
            <h1 class="subtitle is-4 publication-venue"
                style="color:#e63946; display:inline-block; text-align:center; margin:0;">
              NeurIPS Datasets &amp; Benchmarks Track 2025
            </h1>
          </div>



            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://sarthaxxxxx.github.io/" target="_blank">Sarthak Kumar Maharana</a>,</span>
                <span class="author-block"></span>
                  <span class="author-block">
                    <a href="https://sakshamsingh1.github.io/" target="_blank">Saksham Singh Kushwaha</a>,</span>
                    <span class="author-block">
                    <a href="https://www.linkedin.com/in/baoming-zhang-286083313/" target="_blank">Baoming Zhang<sup>*</sup></a>,</span>
                  <span class="author-block">
                    <a href="https://axr2718.github.io/" target="_blank">Adrian Rodriguez<sup>*</sup></a>, </span>
                <span class="author-block">
                    <a href="https://www.linkedin.com/in/songtao-wei/" target="_blank">Songtao Wei<sup>*</sup></a>, </span>
                    <span class="author-block">
                      <a href="https://www.yapengtian.com/" target="_blank">Yapeng Tian</a>,</span>
                  <span class="author-block">
                    <a href="https://yunhuiguo.github.io/" target="_blank">Yunhui Guo</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>*</sup>denotes equal contribution <br>The University of Texas at Dallas, Richardson, TX, USA</span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2506.00358" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/sarthaxxxxx/AVROBUSTBENCH" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
      <a href="https://huggingface.co/datasets/sakshamsingh1/av_robust_data/tree/main" target="_blank"
         class="external-link button is-normal is-rounded is-dark">
        <span class="icon">
          <i class="fas fa-database"></i>
        </span>
        <span>Datasets</span>
      </a>
    </span>

    <span class="link-block">
      <a href="https://www.youtube.com/watch?v=hYdcRO3BuIY&ab_channel=SarthakMaharana" target="_blank"
         class="external-link button is-normal is-rounded is-dark">
        <span class="icon">
          <i class="fab fa-youtube"></i>
        </span>
        <span>Demo</span>
      </a>
    </span>

                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser" style="padding-top: 3rem; padding-bottom: 3rem;">
  <div class="container is-max-desktop">
    <div class="hero-body" style="padding: 2rem 1.5rem;">
    <h2 class="title is-2 has-text-centered" style="margin-bottom: 1.5rem;">Abstract</h2>
    <div class="hero-body">
      <h2 class="subtitle has-text-justified">
        While recent audio-visual models have demonstrated impressive performance, their
robustness to distributional shifts at test-time remains not fully understood. Existing robustness benchmarks mainly focus on single modalities, making them
insufficient for thoroughly assessing the robustness of audio-visual models. Motivated by real-world scenarios where shifts can occur simultaneously in both
audio and visual modalities, we introduce AVROBUSTBENCH, a comprehensive
benchmark designed to evaluate the test-time robustness of audio-visual recognition models. AVROBUSTBENCH comprises four audio-visual benchmark datasets,
AUDIOSET-2C , VGGSOUND-2C , KINETICS-2C , and EPICKITCHENS-2C , each
incorporating 75 bimodal audio-visual corruptions that are co-occurring and correlated. Through extensive evaluations, we observe that state-of-the-art supervised
and self-supervised audio-visual models exhibit declining robustness as corruption
severity increases. Furthermore, online test-time adaptation (TTA) methods, on
VGGSOUND-2C and KINETICS-2C, offer minimal improvements in performance
under bimodal corruptions. We further propose AV2C, a simple TTA approach
enabling on-the-fly cross-modal fusion by penalizing high-entropy samples, which
achieves improvements on VGGSOUND-2C. We hope that AVROBUSTBENCH will steer the development of more effective and robust audio-visual TTA approaches.
    </div>
  </div>
  </div>
</section>

<!-- Teaser image-->

<section class="hero teaser" style="padding: 3rem 0;">
  <div class="container is-max-desktop">
    <h2 class="title is-2 has-text-centered" 
        style="color:#222; font-weight:700; letter-spacing:0.5px; margin-bottom:1.5rem;">
      Problem Overview and Motivation
    </h2>

    <div class="hero-body has-text-centered" style="padding:0;">
      <div class="notification is-danger is-light"
           style="
             font-size: clamp(1.2rem, 2.2vw, 1.55rem);
             font-weight:650;
             line-height:1.8;
             padding:2rem 2.5rem;
             border-left:6px solid #e63946;
             border-radius:14px;
             background: linear-gradient(135deg, #ffeaea 0%, #fff6f6 100%);
             box-shadow:0 4px 14px rgba(0,0,0,0.05);
             max-width:900px;
             margin:0 auto;
             transition:transform 0.3s ease;
           "
           onmouseover="this.style.transform='scale(1.02)'"
           onmouseout="this.style.transform='scale(1)'">
        <span style="display:inline-block; color:#b8001f;">
          Distributional shifts at test-time are <strong>inevitable</strong>, 
          <strong>uncontrollable</strong>, and 
          <strong>hamper learning and generalization</strong>.
          Even state-of-the-art <strong>audio-visual models</strong> 
          still lack serious robustness! ðŸ¥¹
        </span>
      </div>
    </div>
  </div>
</section>





<!-- End teaser image -->

<section class="hero teaser">
  <div class="container is-max-desktop">
    <h3 class="title is-3 has-text-centered">Are SOTA audio-visual models robust enough to such <i>co-occurring and correlated bimodal audio-visual corruptions</i>? Can they be deployed yet with <i>trust</i>?
</h3>
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- ===== 4-image collage with central caption ===== -->
<style>
  .quad-wrap { position: relative; max-width: 980px; margin: 0 auto 1rem auto; }
  .quad-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 0.75rem;
  }
  .quad-card {
    background: #fff;
    border: 1px solid #ececec;
    border-radius: 12px;
    padding: 8px;
    box-shadow: 0 4px 12px rgba(0,0,0,0.06);
  }
  .quad-card img {
    width: 100%;
    height: 100%;
    object-fit: contain; /* keeps plots crisp */
    display: block;
  }
  .quad-caption {
    text-align: center;
    font-weight: 700;
    margin-top: 0.6rem;
    line-height: 1.6;
  }
  .quad-caption .emph { color: #222; }
  .quad-caption .check { color: #6a5acd; } /* âœ… color */
  /* Optional: vertical side label like your figure */
  .quad-side-label {
    position: absolute;
    left: -1.8rem; top: 50%;
    transform: translateY(-50%) rotate(-90deg);
    font-size: 0.8rem; letter-spacing: 0.5px; color: #444;
  }
  @media (max-width: 640px) {
    .quad-grid { grid-template-columns: 1fr; }
    .quad-side-label { display: none; }
  }
</style>

<div class="quad-wrap">

  <div class="quad-grid">
    <!-- Top-left -->
    <div class="quad-card">
      <img src="static/images/p1.png" alt="Recognition plot / bar chart">
    </div>
    <!-- Top-right -->
    <div class="quad-card">
      <img src="static/images/p2.png" alt="CLIP variants comparison">
    </div>
    <!-- Bottom-left -->
    <div class="quad-card">
      <img src="static/images/p3.png" alt="Segmentation drops">
    </div>
    <!-- Bottom-right -->
    <div class="quad-card">
      <img src="static/images/p4.png" alt="Source separation drops">
    </div>
  </div>

   <div class="quad-caption" 
       style="text-align:center; font-size:1.1rem; line-height:1.6; font-weight:500; margin-top:0.75rem;">
    <strong>Top two figures</strong> correspond to <strong>VGGSOUND-2C</strong> and show 
    <strong>recognition results</strong>, while the bottom ones depict 
    <strong>audio-visual segmentation</strong> (bottom-left) and 
    <strong>sound-source separation</strong> (bottom-right). All results are on the respective test sets with our proposed bimodal audio-visual corruptions.
  </div>
</div>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <div class="notification is-danger is-light"
           style="font-size:1.45rem; font-weight:650; line-height:1.8; padding:2rem 1.5rem; border-radius:12px;">
        A rigorous robustness benchmark is needed for audio-visual learning problems!
      </div>
    </div>
  </div>
</section>


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-2 has-text-centered">AVROBUSTBENCH: Benchmark and Contributions</h2>

      <!-- Text summary block -->
      <div class="content has-text-centered" style="max-width: 800px; margin: 1.5rem auto;">
        <p style="font-size:1.15rem; line-height:1.8; text-align:left;">
          <span style="font-size:1.2rem;">âž¤</span> 
          <em style="color:#1a3c7a;">Emulating <strong>real-world settings</strong></em>, we release 
          <span style="color:#1a3c7a; font-weight:600;">realistic, co-occurring, and correlated</span> 
          audio-visual corruptions at test-time. We propose <strong>15 bimodal audio-visual corruptions</strong> each of 5 severity levels,
          categorized into <strong>Digital</strong>, <strong>Environmental</strong>, and <strong>Human-Related</strong> corruptions.
          Our proposed can be easily extended to any audio/speech-visual test sets.
        </p>
      </div>

      <div class="content has-text-centered" style="max-width: 800px; margin: 1.5rem auto;">
        <p style="font-size:1.15rem; line-height:1.8; text-align:left;">
          <span style="font-size:1.2rem;">âž¤</span> 
          We also release four benchmark datasets: 
          <strong>AUDIOSET-2C</strong>, <strong>VGGSOUND-2C</strong>, 
          <strong>KINETICS-2C</strong>, and <strong>EPICKITCHENS-2C</strong>, each containing 
          <strong>75 bimodal audio-visual corruptions</strong> applied on their respective source test sets.
        </p>
      </div>

      <section class="section">
      <div class="container is-max-desktop">
        <h5 class="title is-3 has-text-centered">Examples from AUDIOSET-2C</h5>

        <h5>ðŸ’¡Tip: If inaudible, download the videos to listen with audio.</h5>


        <div class="columns is-multiline is-centered" style="margin-top:1rem;">
      
      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Clean/Source</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_clean.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Gaussian</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_gaussian.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Impulse</h5>
        <video controls  loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_impulse.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Shot</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_shot.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Speckle</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_speckle.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Compression</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_compression.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Snow</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_snow.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Frost</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_frost.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>


      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Spatter</h5>
        <video controls  loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_spatter.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Wind</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_wind.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Rain</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_rain.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>


      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Underwater</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_underwater.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Concert</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_concert.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Smoke</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_smoke.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>


      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Crowd</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_crowd.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="column is-one-quarter-desktop is-one-third-tablet is-half-mobile has-text-centered">
        <h5 class="title is-5" style="margin-bottom:0.5rem;">Interference</h5>
        <video controls loop preload="metadata"
               style="width:100%; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.08);">
          <source src="static/videos/31O2j4aAgYU_interference.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      </div>
      </section>
      

      <div class="content has-text-centered" style="max-width: 800px; margin: 1.5rem auto;">
        <p style="font-size:1.15rem; line-height:1.8; text-align:left;">
          <span style="font-size:1.2rem;">âž¤</span> 
          We propose a <i>simple and effective online test-time adaptation (TTA) method, <strong>AV2C</strong>, to overcome bimodal distributional shifts.</i>  
          <strong>AV2C leverages cross-modal fusion by penalizing high-entropy samples, enabling models to adapt on-the-fly during test-time.</strong>
        </p>
      </div>

    </div>
  </div>
</section>
<!-- End image carousel -->



<!-- RESULTS -->
<section id="results" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-2 has-text-centered">Analysis, Discussions and Takeaways</h2>

    <!-- Tabs -->
    <div class="tabs is-centered is-boxed" style="margin-top:1rem;">
      <ul id="results-tabs">
        <li class="is-active" data-tab="robustness"><a>Robustness of SOTA Audio-Visual Models</a></li>
        <li data-tab="retrieval"><a>AV Retrieval Results</a></li>
        <li data-tab="tta"><a>Online TTA Results</a></li>
        <li data-tab="av-llms"><a>AV-LLMs Results</a></li>
      </ul>
    </div>

    <!-- Tab panels -->
    <div id="results-panels">

      <!-- 1) Robustness of SOTA -->
      <div class="results-panel" data-panel="robustness" style="display:block;">
        <h5 class="title is-5 has-text-centered">Results on limited robustness of SOTA models</h5>
        <div class="card" style="box-shadow:0 6px 20px rgba(0,0,0,0.06); border-radius:14px;">
          <div class="card-image has-text-centered" style="padding:1rem 1rem 0;">
            <img src="static/images/table1.png" alt="SOTA robustness results" class="zoomable" style="max-width:900px; width:100%; border-radius:10px;">
          </div>
          <div class="card-content">
            <p class="is-size-6 has-text-grey">
              We observe a significant gap between clean accuracy and performance under our bimodal AV corruptions (severity 5).
              We report top-1 accuracy, absolute robustness, and relative robustness averaged across corruptions.
              Models include both supervised and self-supervised variants.
            </p>
          </div>
        </div>
      </div>

      <!-- 2) Audio-Visual Retrieval -->
      <div class="results-panel" data-panel="retrieval" style="display:none;">
        <h5 class="title is-5 has-text-centered">Audio-Visual Retrieval Results</h5>
        <div class="columns is-vcentered is-centered" style="margin-top:0.75rem;">
          <div class="column is-half">
            <div class="card" style="box-shadow:0 6px 20px rgba(0,0,0,0.06); border-radius:14px;">
              <div class="card-image has-text-centered" style="padding:1rem 1rem 0;">
                <img src="static/images/table2.png" alt="Retrieval table A" class="zoomable" style="width:100%; border-radius:10px;">
              </div>
              <div class="card-content">
                <p class="is-size-6 has-text-grey has-text-centered">(a) AudioSet-2C &amp; VGGSound-2C</p>
              </div>
            </div>
          </div>
          <div class="column is-half">
            <div class="card" style="box-shadow:0 6px 20px rgba(0,0,0,0.06); border-radius:14px;">
              <div class="card-image has-text-centered" style="padding:1rem 1rem 0;">
                <img src="static/images/table3.png" alt="Retrieval table B" class="zoomable" style="width:100%; border-radius:10px;">
              </div>
              <div class="card-content">
                <p class="is-size-6 has-text-grey has-text-centered">(b) Kinetics-2C &amp; EPIC-Kitchens-2C</p>
              </div>
            </div>
          </div>
        </div>
        <p class="is-size-6 has-text-grey has-text-centered" style="max-width:900px; margin:1rem auto 0;">
          Cross-modal correspondences degrade notably under bimodal AV corruptions at test-time.
        </p>
      </div>

      <!-- 3) Online TTA -->
      <div class="results-panel" data-panel="tta" style="display:none;">
        <h5 class="title is-5 has-text-centered">Online Test-Time Adaptation (TTA) Results</h5>
        <div class="card" style="box-shadow:0 6px 20px rgba(0,0,0,0.06); border-radius:14px;">
          <div class="card-image has-text-centered" style="padding:1rem 1rem 0;">
            <img src="static/images/table4.png" alt="Online TTA results" class="zoomable" style="max-width:900px; width:80%; border-radius:10px;">
          </div>
          <div class="card-content">
            <p class="is-size-6 has-text-grey">
              A sizable gap remains between mean TTA accuracy and the source modelâ€™s clean accuracy on VGGSound (65.50%).
              See paper for per-corruption analyses.
            </p>
          </div>
        </div>
      </div>

      <!-- 4) AV-LLMs -->
      <div class="results-panel" data-panel="av-llms" style="display:none;">
        <h5 class="title is-5 has-text-centered">Are popular AV-LLMs robust to bimodal AV corruptions?</h5>
        <div class="card" style="box-shadow:0 6px 20px rgba(0,0,0,0.06); border-radius:14px;">
          <div class="card-image has-text-centered" style="padding:1rem 1rem 0;">
            <img src="static/images/table5.png" alt="AV-LLMs robustness" class="zoomable" style="max-width:900px; width:70%; border-radius:10px;">
          </div>
          <div class="card-content">
            <p class="is-size-6 has-text-grey">
              In line with supervised/self-supervised models, AV-LLMs also show substantial degradation under audio and visual shifts.
              Advanced prompting or adaptation strategies are promising future directions.
            </p>
          </div>
        </div>
      </div>

    </div>
  </div>
</section>

<!-- Lightbox modal for images -->
<div class="modal" id="img-lightbox">
  <div class="modal-background"></div>
  <div class="modal-content has-text-centered">
    <img id="lightbox-img" src="" alt="" style="max-width:96%; border-radius:12px;">
  </div>
  <button class="modal-close is-large" aria-label="close"></button>
</div>

<script>
// Tabs logic
const tabEls = Array.from(document.querySelectorAll('#results-tabs li'));
const panels = Array.from(document.querySelectorAll('#results-panels .results-panel'));
tabEls.forEach(li => {
  li.addEventListener('click', () => {
    tabEls.forEach(t => t.classList.remove('is-active'));
    li.classList.add('is-active');
    const target = li.getAttribute('data-tab');
    panels.forEach(p => p.style.display = (p.getAttribute('data-panel') === target) ? 'block' : 'none');
  });
});

// Lightbox logic
const modal = document.getElementById('img-lightbox');
const modalImg = document.getElementById('lightbox-img');
document.querySelectorAll('.zoomable').forEach(img => {
  img.style.cursor = 'zoom-in';
  img.addEventListener('click', () => {
    modal.classList.add('is-active');
    modalImg.src = img.src;
    modalImg.alt = img.alt || '';
  });
});
modal.addEventListener('click', () => modal.classList.remove('is-active'));
document.querySelector('#img-lightbox .modal-close')?.addEventListener('click', () => modal.classList.remove('is-active'));
</script>





<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h1 class="title has-text-centered">Citation </h1>
      <h4>If our work is of interest to you, consider citing it. </h4>
      <pre><code>@inproceedings{maharana2025avrobustbench,
        title={AVROBUSTBENCH: Benchmarking the Robustness of Audio-Visual Recognition Models at Test-Time},
        author={Maharana, Sarthak Kumar and Kushwaha, Saksham Singh and Zhang, Baoming and Rodriguez, Adrian and Wei, Songtao and Tian, Yapeng and Guo, Yunhui},
        booktitle={Advances in Neural Information Processing Systems},
        year={2025}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
            <!-- You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative -->
            <!-- Commons Attribution-ShareAlike 4.0 International License</a>. -->
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
