<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sarthak Kumar Maharana</title>
  
  <meta name="author" content="Sarthak Kumar Maharana">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sarthak Kumar Maharana</name>
              </p>

              <p>
                I'm a first-year Computer Science PhD student at the University of Texas at Dallas (<a href="https://www.utdallas.edu/">UTD</a>), advised by <a href = https://yunhuiguo.github.io/> Dr. Yunhui Guo</a>. I'm currently working on designing efficient algorithms related to continual learning for vision.
                Prior to this, I obtained my MS in Electrical Engineering from the University of Southern California (<a href="https://www.usc.edu/">USC</a>) and a Bachelor of Technology (BTech) from International Institute of Information Technology Bhubaneswar (<a href="https://www.iiit-bh.ac.in/">IIIT-Bh</a>), India, with an honors degree in Electrical and Electronics Engineering.              </p>
              <p>
                During my Masters, I closely worked with <a href="https://scholar.google.com/citations?user=sm2Y-6sAAAAJ&hl=en"> Dr. Yonggang Shi</a>. Previously, I had also worked with <a href = "https://scholar.google.com/citations?hl=en&user=8EDHmYkAAAAJ&view_op=list_works&sortby=pubdate">Dr. Shrikanth Narayanan</a>. During my undergraduate studies, I was fortunate enough to work with <a href="https://scholar.google.com/citations?user=rcF7N44AAAAJ&hl=en&oi=ao">Dr. Ren Hongliang</a> (NUS), <a href="https://scholar.google.com/citations?user=B_yn0m0AAAAJ&hl=en"> Dr. Prasanta Kumar Ghosh</a> (IISc), and <a href="https://scholar.google.com/citations?hl=en&user=VYAwEGUAAAAJ"> Dr. Aurobinda Routray</a> (IIT-Kharagpur).
              </p>

	       <p>
                <font color = 'red'> I'm happy to chat and discuss about potential collaborations. Feel free to contact me.</font>
              </p>

              <p style="text-align:center">
                <a href="mailto:sarthakmaharana9811@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Sarthak_CV.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=1sIJMUgAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/sarthaxxxxx/">Github</a> &nbsp/&nbsp
                <a href="www.linkedin.com/in/sarthak9811">LinkedIn</a>
              </p>
            </td>
            <td style="padding:1.5%;width:50%;max-width:50%">
              <a href="images/new.jpg"><img style="width:80%;max-width:100%" alt="profile photo" src="images/new.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				 -->

        </div>
        

      <!-- Education -->
      <!-- <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-education" id="education"><heading>Education</heading></button>
      <div id="content-experience" class="collapse in">
			
        <table border=0 class="bg_colour" style="padding:2px;width:100%;border:2px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>

          <tr>
              <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                      <img src='images/utd.png' width="90" class="side-image">
                  </div>
              </td>
              <td style="padding:1px;width:75%;vertical-align:top">
                   <papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
                  <!-- <papertitle><big>University of Texas at Dallas</big></papertitle>
                  <br>
                  <papertitle style="color:green"><big>Doctor of Philosophy (PhD), </big></papertitle><papertitle><big>Computer Science</big></papertitle>
                  <br>
                </papertitle><papertitle><big>GPA - </big></papertitle> -->
                <!-- <br>
<i>Dallas, TX</i>
                  <br>                              							    
                  August 2023 - May 2027
              </td>
          </tr> -->
      <!-- </tbody></table> --> 

      <!-- <table border=0 class="bg_colour" style="padding:2px;width:100%;border:0px;border-spacing:2px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>

        <tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
                <div class="one">
                    <img src='images/USC-logo.png' width="90" class="side-image">
                </div>
            </td>
            <td style="padding:1px;width:75%;vertical-align:top">
                <<papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
                <!-- <papertitle><big>University of Southern California</big></papertitle>
                <br>
                <papertitle style="color:green"><big>Master of Science (MS), </big></papertitle><papertitle><big>Electrical Engineering</big></papertitle>
                <br>
                <papertitle><big>GPA - 3.85/4</big></papertitle>
                <br> -->
<!-- <i>Los Angeles, CA</i>
<br>
                August 2021 - May 2023
            </td>
        </tr>

    </tbody></table>

    <table border=0 class="bg_colour" style="padding:2px;width:100%;border:0px;border-spacing:2px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>

      <tr>
          <td style="padding:10px;width:25%;vertical-align:middle">
              <div class="one">
                  <img src='images/IIIT.png' width="90" class="side-image">
              </div>
          </td>
          <td style="padding:1px;width:75%;vertical-align:top">
              <papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
              <!-- <papertitle><big>International Institute of Information Technology Bhubaneswar (IIIT-Bh)</big></papertitle>
              <br>
              <papertitle style="color:green"><big>Bachelor of Technology (BTech), </big></papertitle><papertitle><big>Electrical and Electronics Engineering</big></papertitle>
              <br>
              <papertitle><big>GPA - 8.32/10</big></papertitle>
              <br> -->
<!-- <i>Bhubaneswar, India</i>
<br>
              August 2016 - June 2020
          </td> -->
      <!-- </tr> --> 

  <!-- </tbody></table> --> 

</div>


      <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-education" id="education"><heading>News</heading></button>
      <div id="content-experience" class="collapse in">
                <!-- <div class="scroll">  -->

                <table border=0 class="bg_colour" style="padding:10px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  
                  <tr>
                    <td>
                        <p style="color:green; display:inline">Aug '23 &nbsp</p>
                    </td>
                    <td>
                    Started PhD @ UTD. 
                    </td>
                </tr>

                  <tr>
                    <td>
                        <p style="color:green; display:inline">May '23 &nbsp</p>
                    </td>
                    <td>
                    Graduated from USC with an MS in Electrical Engineering. 
                    </td>
                </tr>
      
                  <tr>
                        <td>
                            <p style="color:green; display:inline">Mar '23 &nbsp</p>
                        </td>
                        <td>
				Accepted the CS PhD offer from UTD.
                        </td>
                    </tr>
                  
                  <tr>
                      <td>
                          <p style="color:green; display:inline">Aug '21 &nbsp</p>
                      </td>
                      <td>
                          Started MS in Electrical Engineering at USC.
                      </td>
                  </tr>

                  <tr>
                    <td>
                      <p style="color:green; display:inline">June '21 &nbsp</p>
                    </td>
                    <td>
                      Virtually presented the paper on acoustic-to-articulatory inversion of dysarthric speech at IEEE ICASSP 2021.
                    </td>
                  </tr>
			
			<tr>
                        <td>
                            <p style="color:green; display:inline">Mar '21 &nbsp</p>
                        </td>
                        <td>
				Our paper got accepted to IEEE ICASSP 2021.
                        </td>
                    </tr>	

			
			<tr>
                        <td>
                            <p style="color:green; display:inline">Jun '20 &nbsp</p>
                        </td>
                        <td>
				Graduated from IIIT-Bh with a BTech (Honors) in Electrical and Electronics Engineering.
                        </td>
                    </tr>

                    <tr>
                      <td>
                          <p style="color:green; display:inline">Nov '19 &nbsp</p>
                      </td>
                      <td>
      Paper on harmonic analysis of a PV hysteresis current control inverted got accepted to IEEE ICSSIT 2019.
                      </td>
                  </tr>


                </tbody>
              </table>
                <!-- </div> -->
                <!-- </div> -->
                <!-- </div> -->
                <!--  -->

              </div>
              
              <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-education" id="education"><heading>Research</heading></button>
              <div id="content-experience" class="collapse in">
              <table border=0 class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
              <tr>
              <ul>
                <li>Continual (Lifelong) learning</li>
                <li>Data and parameter efficient deep learning</li>
                <li>Self-supervised learning, graph representation learning</li>
                <li>Human-centered AI, that includes multi-modal machine learning with applications to speech and medical images</li>
                <!-- <li>I'm primarily interested in human-centered AI, which includes multi-modal machine learning with applications to speech and medical images. On the whole, my interests lie in self-supervised learning, video representation learning, generative models, etc.</li> -->
              </td>
              </tr>
              </tbody>


              <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-education" id="education"><heading>Publications / Preprints</heading></button>
              <div id="content-experience" class="collapse in">
                  <!-- <table border=0 class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
                   <tr>
                    <ul>
                      <li>I'm primarily interested in human-centered AI, which includes multi-modal machine learning with applications to speech and medical images. On the whole, my interests lie in self-supervised learning, video representation learning, generative models, etc.</li>
                  </td>
                  </tr>
                  </tbody>
                </table> -->

                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                     <div class="one">
                       <!-- <div class="two" id='neurips_image'>
                            <a href="images/propsed.png"><img style="width:110%;max-width:130%;height:85%;" alt="" src="images/propsed.png" class="hoverZoomLink"></a>
                      </div> -->
                    </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="">
                      <papertitle>Acoustic-to-Articulatory Inversion for Dysarthric Speech: Are Pre-Trained Self-Supervised Representations Favorable? [PREPRINT]
                      </papertitle>
                      </a>
                      <br>
                      <strong>Sarthak Kumar Maharana</strong>,
                      <a href="https://www.linkedin.com/in/krishna-kamal">Krishna Kamal Adidam</a>,
                      <a href='https://www.linkedin.com/in/shoumik-nandi-766b82175'>Shoumik Nandi</a>,
                      <a href="https://www.ajitesh-srivastava.com/">Ajitesh Srivastava</a>
                      <br>
                      <!-- <em>International Conference of Acoustics, Speech, and Signal Processing (ICASSP)</em> 2021 <br> -->
                      <!-- <em>ECCV 2022 Workshop on Visual Object-oriented Learning meets Interaction (VOLI): Discovery, Representations, and Applications</em> -->
                      <br>
                      <a href="https://arxiv.org/abs/2309.01108">[Paper]</a> 
                      <br>
                      <p></p>
                      <p>Acoustic-to-articulatory inversion (AAI) involves mapping from the acoustic space to the articulatory space. Signal-processing features like the MFCCs, have been widely used for the AAI task. For subjects with dysarthric speech, AAI is challenging because of an imprecise and indistinct pronunciation. In this work, we perform AAI for dysarthric speech using representations from pre-trained self-supervised learning (SSL) models. We demonstrate the impact of different pre-trained features on this challenging AAI task, at low-resource conditions. In addition, we also condition x-vectors to the extracted SSL features to train a BLSTM network. Overall, SSL networks like wav2vec, APC, and DeCoAR, which are trained with feature reconstruction or future timestep prediction tasks, perform well in predicting dysarthric articulatory trajectories.</p>
                    </td>
                  </tr>

                   <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
                      <td style="padding:20px;width:25%;vertical-align:middle">
                       <div class="one">
                          <div class="two" id='neurips_image'>
                              <a href="images/icassp.png"><img style="width:110%;max-width:110%;height:75%;" alt="" src="images/icassp.png" class="hoverZoomLink"></a>
                        </div>
                      </div>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="">
                        <papertitle>Acoustic-to-Articulatory Inversion for Dysarthric Speech by Using Cross-Corpus Acoustic-Articulatory Data</papertitle>
                        </a>
                        <br>
                        <strong>Sarthak Kumar Maharana</strong>,
                        <a href="https://in.linkedin.com/in/aravind-illa-13a84658">Aravind Illa</a>,
                        <a href='https://www.linkedin.com/in/renuka-mannem-17686617a'>Renuka Mannem</a>,
                        Yamini Bellur, Veeramani Preethish Kumar, Seena Vengalil, Kiran Polavarapu, Nalini Atchayaram,
                        <a href="https://scholar.google.com/citations?hl=en&user=B_yn0m0AAAAJ&view_op=list_works">Prasanta Kumar Ghosh</a>
                        <br>
                        <em>IEEE International Conference of Acoustics, Speech, and Signal Processing (ICASSP)</em> 2021 <br>
                        <!-- <em>ECCV 2022 Workshop on Visual Object-oriented Learning meets Interaction (VOLI): Discovery, Representations, and Applications</em> -->
                        <br>
                        <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:qks0yUjnpGsJ:scholar.google.com/&output=citation&scisdr=ClGT-4YPEMLP2VuiMZQ:AFWwaeYAAAAAZPqkKZS7Nl0vfUdvI_i5NHipe2c&scisig=AFWwaeYAAAAAZPqkKdQi3i0lt4hyyM-OJYM07LA&scisf=4&ct=citation&cd=-1&hl=en">[BibTeX]</a>
                        <a href="https://ieeexplore.ieee.org/document/9413625">[Paper]</a> 
                        <a href="https://github.com/sarthaxxxxx/AAI-ALS">[Code]</a> 
                        <a href="https://drive.google.com/file/d/1Oj19XvG26dIKCfwjDhqt0rrEnfbVrwFK/view?usp=sharing">[Video]</a>
                        <br>
                        <p></p>
                        <p>In this work, we focus on estimating articulatory movements from acoustic features, known as acoustic-to-articulatory inversion (AAI), for dysarthric patients with amyotrophic lateral sclerosis (ALS). Unlike healthy subjects, there are two potential challenges involved in AAI on dysarthric speech. Due to speech impairment, the pronunciation of dysarthric patients is unclear and inaccurate, which could impact the AAI performance. In addition, acoustic-articulatory data from dysarthric patients is limited due to the difficulty in recording. These challenges motivate us to utilize cross-corpus acoustic-articulatory data. In this study, we propose an AAI model by conditioning speaker information using x-vectors at the input, and multi-target articulatory trajectory outputs for each corpus separately. </p>
                      </td>
                    </tr>


                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                      <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                         <div class="one">
                            <div class="two" id='neurips_image'>
                                <a href="images/powergui.png"><img style="width:110%;max-width:110%;height:90%;" alt="" src="images/powergui.png" class="hoverZoomLink"></a>
                          </div>
                        </div>
                        </td>
                        <td style="padding:20px;width:90%;vertical-align:middle">
                          <a href="">
                          <papertitle>Harmonics analysis of a PV integrated hysteresis current control inverter connected with grid and without grid</papertitle>
                          </a>
                          <br>
                          Jayanta Kumar Sahu, Sudhakar Sahu, J.P Patra,
                          <strong>Sarthak Kumar Maharana</strong>, Bhagabat Panda
                          <br>
                          <em>IEEE International Conference on Smart Systems and Inventive Technology (ICSSIT)</em> 2019 <br>
                          <!-- <em>ECCV 2022 Workshop on Visual Object-oriented Learning meets Interaction (VOLI): Discovery, Representations, and Applications</em> -->
                          <br>
                          <a href = "https://scholar.googleusercontent.com/scholar.bib?q=info:DOqHloR39YQJ:scholar.google.com/&output=citation&scisdr=ClGT-4YPEMLP2Vulqxw:AFWwaeYAAAAAZPqjsxwWTw5uzNsKkYxdbxISbYE&scisig=AFWwaeYAAAAAZPqjsyr7R9lqiNlL3vb_zKrtG4I&scisf=4&ct=citation&cd=-1&hl=en">[BibTeX]</a>
                          <a href="https://ieeexplore.ieee.org/abstract/document/8987864">[Paper]</a> 
                          <!-- <a href="https://github.com/sarthaxxxxx/AAI-ALS">Code</a> / -->
                          <!-- <a href="https://drive.google.com/file/d/1hukbcGmI6zk4Rrq9H-tE35YoC5V6dbjs/view?usp=sharing">Video</a> -->
                          <br>
                          <p></p>
                          <p>Generally, two devices are responsible for the generation of time-variant power. They are alternators and inverters. Harmonics are the unwanted signals generally created on the output of the inverter. In this paper, hysteresis current control inverters are described. Here the HCC inverters are connected with a grid and without a grid and integrated with a photo voltaic panel. The HCC inverters are connected to the grid with the help of a phase lock loop. Finally, the total harmonics distortion is calculated in this model their results are compared based on total harmonics distortion. </p>
                        </td>
                      </tr>
                      </tbody></table>


                    </div>
                    

          <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-education" id="education"><heading>Research Experiences</heading></button>
          <div id="content-experience" class="collapse in">
          <table border=0 class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>

          <tr>
              <td style="padding:10px;width:25%;vertical-align:middle">
                  <div class="one">
                      <img src='images/USC-logo.png' width="90" class="side-image">
                  </div>
              </td>
              <td style="padding:10px;width:75%;vertical-align:top">
                  <!-- <papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
                  <papertitle><big>University of Southern California</big></papertitle>
                  <br>
                  <papertitle style="color:green"><big>Graduate Research Assistant</big></papertitle>
                  <br>
<i>Los Angeles, CA</i>
                  <br>                              							    
                  May 2022 - July 2023
                  <br>
                  <br>
                  <p>
                      
                      <ul>
                          <li><b>Supervisor -</b> <a href="https://scholar.google.com/citations?user=sm2Y-6sAAAAJ&hl=en"> Dr. Yonggang Shi </a></li>
                          <li><b>Activities - </b>
                            <ul>
                              <li> Developed an end-to-end general software tool to automate the reconstruction of fiber bundles in the brainstem of the human brain, using diffusion
                                MRI images, for the HCP Aging dataset (to be publicly released soon).</li>
                              <li> Leveraged deep learning based registration and label fusion methods to automatically generate the anatomical ROIs that are critical for fiber
                                bundle reconstruction.</li>
                          </li>
                      </ul>
                  </p>
              </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
                <div class="one">
                    <img src='images/USC-logo.png' width="90" class="side-image">
                </div>
            </td>
            <td style="padding:10px;width:75%;vertical-align:top">
                <!-- <papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
                <papertitle><big>University of Southern California</big></papertitle>
                <br>
                <papertitle style="color:green"><big>Student Researcher</big></papertitle>
                <br>
<i>Los Angeles, CA</i>
                <br>                              							    
                Dec 2021 - Dec 2022
                <br>
                <br>
                <p>
                    
                    <ul>
                        <li><b>Supervisor -</b> <a href="https://scholar.google.com/citations?hl=en&user=8EDHmYkAAAAJ&view_op=list_works&sortby=pubdate"> Dr. Shrikanth (Shri) Narayanan </a></li>
                        <li><b>Activities - </b>
                          <ul>
                            <li> Performed speaker recognition from rt-MRI videos, based on an unsupervised disentanglement representation learning scheme.</li>
                            <li> Contributed to the development of generating embeddings from 2D sagittal-view rt-MRI videos to distinguish between speakers based on their
                              articulatory representations from vocal tract landmarks.</li>
                        </li>
                    </ul>
                </p>
            </td>
        </tr>

        <tr>
          <td style="padding:10px;width:25%;vertical-align:middle">
              <div class="one">
                  <img src='images/nus_logo.jpg' width="120" class="side-image">
              </div>
          </td>
          <td style="padding:10px;width:75%;vertical-align:top">
              <!-- <papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
              <papertitle><big>National University of Singapore</big></papertitle>
              <br>
              <papertitle style="color:green"><big>Part-time Research Assistant</big></papertitle>
              <br>
<i>Remote</i>
              <br>                              							    
              July 2020 - Apr 2021
              <br>
              <br>
              <p>
                  
                  <ul>
                      <li><b>Supervisor -</b> <a href="https://scholar.google.com/citations?user=rcF7N44AAAAJ&hl=en&oi=ao"> Dr. Ren Hongliang </a></li>
                      <li><b>Activities - </b>
                        <ul>
                          <li>Experimented with different encoder-decoder architectures (ex. LinkNet) by plugging in spatio-temporal modules (ex. convLSTM) to perform
                            pixel-wise prediction of the needle trajectory in ultrasound images during a kidney biopsy.</li>
                          <li> Proposed the integration of a DGMN (Dynamic Graph Message Passing) network in DGCN (Dual Graph Convolutional Network), for efficient
                            semantic segmentation, to model long-range dependencies in an OCT image.</li>
                      </li>
                  </ul>
              </p>
          </td>
      </tr>

      <tr>
        <td style="padding:10px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='images/iisc.jpg' width="90" class="side-image">
            </div>
        </td>
        <td style="padding:10px;width:75%;vertical-align:top">
            <!-- <papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
            <papertitle><big>Indian Institute of Science</big></papertitle>
            <br>
            <papertitle style="color:green"><big>Bachelor's Thesis and Student Researcher</big></papertitle>
            <br>
<i>Bangalore, India</i>
            <br>                              							    
            Dec 2019 - Sep 2020
            <br>
            <br>
            <p>
                
                <ul>
                    <li><b>Supervisor -</b> <a href="https://scholar.google.com/citations?user=B_yn0m0AAAAJ&hl=en"> Dr. Prasanta Ghosh </a></li>
                    <li><b>Activities - </b>
                      <ul>
                        <li>Studied acoustic-to-articulatory inversion (AAI) model‚Äôs performance on the dysarthric speech when the model was trained in a corpus dependent
                          manner using a matched low-resource dysarthric corpus or using a mismatched cross-corpus with rich acoustic-articulatory data.</li>
                        <li> Investigated the benefit of utilizing cross-corpus acoustic-articulatory data using transfer learning and joint-training techniques for the articulatory
                          predictions of dysarthric subjects.</li>
                    </li>
                </ul>
            </p>
        </td>
    </tr>

    <tr>
      <td style="padding:10px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/iitkgp.png' width="110" class="side-image">
          </div>
      </td>
      <td style="padding:10px;width:75%;vertical-align:top">
          <!-- <papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
          <papertitle><big>Indian Institute of Technology Kharagpur</big></papertitle>
          <br>
          <papertitle style="color:green"><big>Summer Research Intern</big></papertitle>
          <br>
<i>Kharagpur, India</i>
          <br>                              							    
          May 2019 - Jul 2019
          <br>
          <br>
          <p>
              
              <ul>
                  <li><b>Supervisor -</b> <a href="https://scholar.google.co.in/citations?hl=en&user=VYAwEGUAAAAJ&view_op=list_works"> Dr. Aurobinda Routray </a></li>
                  <li><b>Activities - </b>
                    <ul>
                      <li>Developed an in-house template matching algorithm, of various phases, to detect breaths in speech recordings using end-to-end deep neural
                        networks.</li>
                      <li>Employed a heuristic technique to join close predicted breath segments, and segments below a certain threshold were removed, for postprocessing
                        and to remove any misclassification errors.</li>
                  </li>
              </ul>
          </p>
      </td>
  </tr>
          </tbody></table>

        </div>


          <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-education" id="education"><heading>Awards</heading></button>
          <div id="content-experience" class="collapse in">
          <table border=0 class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
            <tr>
              <ul>
                <li>Fully funded tuition, with a stipend, to pursue CS PhD at UTD.</li>
                <li>Governing Body Merit Scholarship (April 2021).</li>
                <font color="grey" style="italic" size="2pt"><em>&nbsp&nbsp Awarded to top 3 students of each department at IIIT-Bh. 
                  Received for the academic year 2019-2020.</em></font>
                <li>Indian Academy of Sciences (IAS) - Summer Research Fellowship (April 2019)</li>
                <font color="grey" style="italic" size="2pt"><em>&nbsp&nbsp An annual research fellowship program (<10% selection rate) conducted by the Indian Academy of Sciences, under IISc Bangalore.</em></font>
            </td>
            </tr>
            </tbody>
          </table>
        

          <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-education" id="education"><heading>Academic/Volunteer Work</heading></button>
          <div id="content-experience" class="collapse in">
          <table border=0 class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
            <tr>
              <ul>
		<li>I'm TAing two undergraduate CS classes at UTD, this Fall - CS 4365 and CS 4348. </li>
                <li>Building <a href="https://cordai.org/">CORD.ai</a>, a deep learning research community, as a core member and volunteer researcher. </li>
                <li>Course Mentor/Grader for graduate level EE 541: An Introduction to Deep Learning (Spring 2022).</li>
                <li>USC IEEE Graduate Society - Member, strengthen academic and social growth of the members, and host workshops.</li>
                <li>PyCon India 2020 - Content writer for social media handles, helped the promotions team to reach out to organizations and colleges, and interacted
                  with individuals who have contributed to the language, and also worked on creating virtual swags.</li>
            </td>
            </tr>
            </tbody>
          </table>

          <button style="border:0px transparent; background-color: transparent;outline:none;"type="button" class="collapsible" data-toggle="collapse" data-target="#content-education" id="education"><heading>Miscellaneous</heading></button>
          <div id="content-experience" class="collapse in">
          <table border=0 class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
            <tr>
              <ul>
                <li>I'm a cis male.</li>
                <li>I consider myself lucky to have grown up in two beautiful cities in India - Bangalore and Bhubaneswar, that have infused in me a lot of character and development. I've also spent two quality years in the vibrant, diverse, gently warm, and sprawling city of Los Angeles, California. Absolutely look forward to staying in new places and experiencing different cultures.</li>
                <li>I'm a HUGE fan of the classical formats of cricket. You'd often find me watching old test match highlights or SRT straight drives. Nothing can get more sublime than that. I bet! I don't consider IPL/T20 cricket as a thing AT ALL.</li>
                <li>I think mobile photography is like a side gig for me? My phone instantly comes out the moment my eyes catch sight of a beautiful view.</li>
                <li>I also spend a lot of time in quality humor - dark humor per se. We could talk about that later.</li>
            </td>
            </tr>
            </tbody>
          </table>

          
          

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:1px">
                <br>
                <p style="text-align:right;font-size:small;">
                   <a href="https://github.com/jonbarron/jonbarron_website">Source code</a> by Jon Barron.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
                  

                    
</body>

</html>
